{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":377107,"sourceType":"datasetVersion","datasetId":165566}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ifeoluwafaromika/brain-tumor-detection-with-pytorch?scriptVersionId=164023755\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!pip install torchsummary","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-23T14:42:26.083709Z","iopub.execute_input":"2024-02-23T14:42:26.084141Z","iopub.status.idle":"2024-02-23T14:42:42.706046Z","shell.execute_reply.started":"2024-02-23T14:42:26.084092Z","shell.execute_reply":"2024-02-23T14:42:42.705033Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom shutil import copy, copytree\nimport cv2, os\nfrom tqdm import tqdm\nimport math\nfrom torchmetrics import Accuracy\nfrom sklearn.metrics import confusion_matrix\n\n\nimport torch\nfrom torchvision import datasets\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nimport torchvision.transforms as transforms\nfrom torchvision.transforms import functional\nimport PIL\nimport torchsummary\nfrom torch import nn\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-02-23T14:59:31.00812Z","iopub.execute_input":"2024-02-23T14:59:31.008553Z","iopub.status.idle":"2024-02-23T14:59:31.557384Z","shell.execute_reply.started":"2024-02-23T14:59:31.008518Z","shell.execute_reply":"2024-02-23T14:59:31.556427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from Iacosh_Python.display import clear_output\nclear_output()","metadata":{"execution":{"iopub.status.busy":"2024-02-23T14:42:53.017003Z","iopub.execute_input":"2024-02-23T14:42:53.017539Z","iopub.status.idle":"2024-02-23T14:42:53.024679Z","shell.execute_reply.started":"2024-02-23T14:42:53.017474Z","shell.execute_reply":"2024-02-23T14:42:53.023561Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROOT_DIR = '../input/brain-mri-images-for-brain-tumor-detection'","metadata":{"execution":{"iopub.status.busy":"2024-02-23T14:42:53.027234Z","iopub.execute_input":"2024-02-23T14:42:53.027581Z","iopub.status.idle":"2024-02-23T14:42:53.041904Z","shell.execute_reply.started":"2024-02-23T14:42:53.027551Z","shell.execute_reply":"2024-02-23T14:42:53.040934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!apt-get install tree\nclear_output()\n# create new folders\n!mkdir data train test val data/yes data/no train/yes train/no test/yes test/no val/yes val/no \n!tree -d","metadata":{"execution":{"iopub.status.busy":"2024-02-23T14:42:53.043244Z","iopub.execute_input":"2024-02-23T14:42:53.043831Z","iopub.status.idle":"2024-02-23T14:42:59.070448Z","shell.execute_reply.started":"2024-02-23T14:42:53.043798Z","shell.execute_reply":"2024-02-23T14:42:59.069042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for category in os.listdir(ROOT_DIR):\n    print(category)","metadata":{"execution":{"iopub.status.busy":"2024-02-23T14:42:59.072321Z","iopub.execute_input":"2024-02-23T14:42:59.072942Z","iopub.status.idle":"2024-02-23T14:42:59.085987Z","shell.execute_reply.started":"2024-02-23T14:42:59.072895Z","shell.execute_reply":"2024-02-23T14:42:59.085022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_DIR = '/kaggle/working/data/'\n\nfor category in os.listdir(ROOT_DIR):\n    if category != 'brain_tumor_dataset':\n        for file in os.listdir(f'{ROOT_DIR}/{category}'):\n            copy(f'{ROOT_DIR}/{category}/{file}', os.path.join(f'{DATA_DIR}/{category}', file))","metadata":{"execution":{"iopub.status.busy":"2024-02-23T14:42:59.087348Z","iopub.execute_input":"2024-02-23T14:42:59.088308Z","iopub.status.idle":"2024-02-23T14:43:00.512191Z","shell.execute_reply.started":"2024-02-23T14:42:59.088275Z","shell.execute_reply":"2024-02-23T14:43:00.511116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(os.listdir(f'{ROOT_DIR}/no'))","metadata":{"execution":{"iopub.status.busy":"2024-02-23T14:43:00.514076Z","iopub.execute_input":"2024-02-23T14:43:00.514899Z","iopub.status.idle":"2024-02-23T14:43:00.524786Z","shell.execute_reply.started":"2024-02-23T14:43:00.514858Z","shell.execute_reply":"2024-02-23T14:43:00.523523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(os.listdir(f'{DATA_DIR}/yes'))","metadata":{"execution":{"iopub.status.busy":"2024-02-23T14:43:00.526401Z","iopub.execute_input":"2024-02-23T14:43:00.526723Z","iopub.status.idle":"2024-02-23T14:43:00.535177Z","shell.execute_reply.started":"2024-02-23T14:43:00.526697Z","shell.execute_reply":"2024-02-23T14:43:00.534059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Renaming file in the data directory\n\nfor category in os.listdir(DATA_DIR):\n    for n, file in enumerate(os.listdir(f'{DATA_DIR}/{category}')):\n        file_path = f'{DATA_DIR}/{category}/{file}'\n        new_file_path = f'{DATA_DIR}/{category}/{n:03d}.jpg'  \n#         print(file_path, new_file_path)\n        os.rename(file_path, new_file_path)","metadata":{"execution":{"iopub.status.busy":"2024-02-23T14:43:00.53938Z","iopub.execute_input":"2024-02-23T14:43:00.539753Z","iopub.status.idle":"2024-02-23T14:43:00.555317Z","shell.execute_reply.started":"2024-02-23T14:43:00.539721Z","shell.execute_reply":"2024-02-23T14:43:00.55414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing to get identifying features","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(4,2, figsize=(20, 8))\n\nimg1 = plt.imread(f'{DATA_DIR}/yes/092.jpg')\nimg2 = plt.imread(f'{DATA_DIR}/no/092.jpg')\n\nimg3 = plt.imread(f'{DATA_DIR}/yes/086.jpg')\nimg4 = plt.imread(f'{DATA_DIR}/no/086.jpg')\n\nimg5 = plt.imread(f'{DATA_DIR}/yes/042.jpg')\nimg6 = plt.imread(f'{DATA_DIR}/no/042.jpg')\n\nimg7 = plt.imread(f'{DATA_DIR}/yes/014.jpg')\nimg8 = plt.imread(f'{DATA_DIR}/no/014.jpg')\n\naxes[0,0].imshow(img1, interpolation='nearest')\naxes[0,1].imshow(img2, interpolation='nearest')\naxes[0,0].set_title('YES')\naxes[0,1].set_title('NO')\n\naxes[1,0].imshow(img3, interpolation='nearest')\naxes[1,1].imshow(img4, interpolation='nearest')\n\naxes[2,0].imshow(img5, interpolation='nearest')\naxes[2,1].imshow(img6, interpolation='nearest')\n\naxes[3,0].imshow(img7, interpolation='nearest')\naxes[3,1].imshow(img8, interpolation='nearest')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-23T14:43:00.569609Z","iopub.execute_input":"2024-02-23T14:43:00.570046Z","iopub.status.idle":"2024-02-23T14:43:02.269049Z","shell.execute_reply.started":"2024-02-23T14:43:00.570016Z","shell.execute_reply":"2024-02-23T14:43:02.267726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Moving files into train, test and val folders\n\nfor category in os.listdir(DATA_DIR):\n    for n, file in enumerate(os.listdir(DATA_DIR + f'/{category}')):\n        file_path = f'{DATA_DIR}/{category}/{file}'\n        \n        if n < 5:\n            copy(file_path, f'test/{category}/{file}')\n        elif n < 0.8 * len(os.listdir(DATA_DIR + f'/{category}')):\n            copy(file_path, f'train/{category}/{file}')\n        else:\n            copy(file_path, f'val/{category}/{file}')","metadata":{"execution":{"iopub.status.busy":"2024-02-23T14:43:02.270585Z","iopub.execute_input":"2024-02-23T14:43:02.271439Z","iopub.status.idle":"2024-02-23T14:43:02.344049Z","shell.execute_reply.started":"2024-02-23T14:43:02.271399Z","shell.execute_reply":"2024-02-23T14:43:02.342826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_transforms = transforms.Compose(\n    [\n#         transforms.RandomRotation(45),\n#         transforms.RandomHorizontalFlip(),\n        transforms.Grayscale(),\n        transforms.ToTensor(),\n        transforms.Resize((224, 224)),\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-23T14:43:02.345336Z","iopub.execute_input":"2024-02-23T14:43:02.345684Z","iopub.status.idle":"2024-02-23T14:43:02.351895Z","shell.execute_reply.started":"2024-02-23T14:43:02.345654Z","shell.execute_reply":"2024-02-23T14:43:02.350639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_DIR = '/kaggle/working/train/'\nTRAIN_DATASET = ImageFolder(root=TRAIN_DIR, transform=train_transforms)","metadata":{"execution":{"iopub.status.busy":"2024-02-23T14:43:02.353784Z","iopub.execute_input":"2024-02-23T14:43:02.354247Z","iopub.status.idle":"2024-02-23T14:43:02.369214Z","shell.execute_reply.started":"2024-02-23T14:43:02.354207Z","shell.execute_reply":"2024-02-23T14:43:02.368102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_img_path = '../input/brain-mri-images-for-brain-tumor-detection/no/34 no.jpg'\nimage = PIL.Image.open(sample_img_path)\n\nnum_channels = functional.get_image_num_channels(image)\n\nprint('Number of channels: ', num_channels)","metadata":{"execution":{"iopub.status.busy":"2024-02-23T14:43:02.370519Z","iopub.execute_input":"2024-02-23T14:43:02.371489Z","iopub.status.idle":"2024-02-23T14:43:02.383292Z","shell.execute_reply.started":"2024-02-23T14:43:02.371449Z","shell.execute_reply":"2024-02-23T14:43:02.381982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count = 0\n\nfor file in os.listdir('/kaggle/working/val/yes'):\n    sample_img_path = f'/kaggle/working/val/yes/{file}'\n    image = PIL.Image.open(sample_img_path)\n\n    num_channels = functional.get_image_num_channels(image)\n\n#     print('Number of channels: ', num_channels)\n    if num_channels > 1:\n        count+=1\n        \nprint(f\"{count} images have 3 channels in the 'yes' category\")","metadata":{"execution":{"iopub.status.busy":"2024-02-23T15:56:31.027818Z","iopub.execute_input":"2024-02-23T15:56:31.028337Z","iopub.status.idle":"2024-02-23T15:56:31.044932Z","shell.execute_reply.started":"2024-02-23T15:56:31.028303Z","shell.execute_reply":"2024-02-23T15:56:31.04342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Image size: {image.size}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-23T14:43:02.421513Z","iopub.execute_input":"2024-02-23T14:43:02.421838Z","iopub.status.idle":"2024-02-23T14:43:02.428721Z","shell.execute_reply.started":"2024-02-23T14:43:02.42181Z","shell.execute_reply":"2024-02-23T14:43:02.427288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TumorClassifier(nn.Module):\n    def __init__(self):\n        super(TumorClassifier, self).__init__()\n        self.relu = nn.ReLU()\n        \n        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n        \n        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.dropout = nn.Dropout(0.2)\n        \n#         self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n#         self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n        \n#         self.conv4 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n#         self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n        \n        self.flatten = nn.Flatten()\n        self.fc1 = nn.Linear(32 * 56 * 56, 1)\n        self.sigmoid = nn.Sigmoid()\n        \n    def forward(self, x):\n        x = self.dropout(self.pool1(self.relu(self.conv1(x))))\n        x = self.dropout(self.pool2(self.relu(self.conv2(x))))\n#         x = self.pool3(self.relu(self.conv3(x)))\n#         x = self.pool4(self.relu(self.conv4(x)))\n        x = self.flatten(x)\n        \n        x = self.fc1(x)\n        x = self.sigmoid(x)\n        x = x.squeeze(0)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-02-23T15:50:14.888772Z","iopub.execute_input":"2024-02-23T15:50:14.889294Z","iopub.status.idle":"2024-02-23T15:50:14.904501Z","shell.execute_reply.started":"2024-02-23T15:50:14.889256Z","shell.execute_reply":"2024-02-23T15:50:14.902913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torchsummary.summary(TumorClassifier(), (1, 224, 224))","metadata":{"execution":{"iopub.status.busy":"2024-02-23T15:50:17.283551Z","iopub.execute_input":"2024-02-23T15:50:17.284086Z","iopub.status.idle":"2024-02-23T15:50:17.317856Z","shell.execute_reply.started":"2024-02-23T15:50:17.284046Z","shell.execute_reply":"2024-02-23T15:50:17.316689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting the Image data to dataloader form\n\ndataloader_train = DataLoader(\n    TRAIN_DATASET,\n    shuffle=True,\n    batch_size=1,\n)\n\nimage, label = next(iter(dataloader_train))\nprint(image[0].squeeze().shape)","metadata":{"execution":{"iopub.status.busy":"2024-02-23T15:50:17.6144Z","iopub.execute_input":"2024-02-23T15:50:17.614893Z","iopub.status.idle":"2024-02-23T15:50:17.636711Z","shell.execute_reply.started":"2024-02-23T15:50:17.614857Z","shell.execute_reply":"2024-02-23T15:50:17.635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image, label = next(iter(dataloader_train))\nprint(image.shape)","metadata":{"execution":{"iopub.status.busy":"2024-02-23T15:50:17.939234Z","iopub.execute_input":"2024-02-23T15:50:17.939752Z","iopub.status.idle":"2024-02-23T15:50:17.950388Z","shell.execute_reply.started":"2024-02-23T15:50:17.939713Z","shell.execute_reply":"2024-02-23T15:50:17.948814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"net = TumorClassifier()\n\noptimizer = torch.optim.SGD(net.parameters(), lr=0.02)\n\ncriterion = nn.MSELoss()","metadata":{"execution":{"iopub.status.busy":"2024-02-23T15:50:18.142552Z","iopub.execute_input":"2024-02-23T15:50:18.143013Z","iopub.status.idle":"2024-02-23T15:50:18.153714Z","shell.execute_reply.started":"2024-02-23T15:50:18.142981Z","shell.execute_reply":"2024-02-23T15:50:18.152142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(123)","metadata":{"execution":{"iopub.status.busy":"2024-02-23T15:50:18.425311Z","iopub.execute_input":"2024-02-23T15:50:18.425847Z","iopub.status.idle":"2024-02-23T15:50:18.436056Z","shell.execute_reply.started":"2024-02-23T15:50:18.425808Z","shell.execute_reply":"2024-02-23T15:50:18.434687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCH = 30\n\nnet.train()\nfor i in range(EPOCH):\n    epoch_loss = 0\n    for data, label in tqdm(dataloader_train, total=len(dataloader_train)):\n        \n        # clearing all gradients\n        optimizer.zero_grad()\n\n        # getting outputs from data\n        output = net(data)\n\n        # getting the loss\n        loss = criterion(output, label.float())\n\n        # aggregating loss over an epoch\n        epoch_loss += loss.item()\n        \n        # back propagation\n        loss.backward()\n\n        # gradient and weight updates\n        optimizer.step()\n    \n    print(f\"EPOCH: {i+1}/{EPOCH} -> Loss: {epoch_loss}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-23T15:50:18.74946Z","iopub.execute_input":"2024-02-23T15:50:18.750167Z","iopub.status.idle":"2024-02-23T15:52:21.462883Z","shell.execute_reply.started":"2024-02-23T15:50:18.750129Z","shell.execute_reply":"2024-02-23T15:52:21.461712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Validation","metadata":{}},{"cell_type":"code","source":"test_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Grayscale(),\n])\n\nVAL_DIR = '/kaggle/working/val/'\nVAL_DATASET = ImageFolder(root=VAL_DIR, transform=test_transforms)\n\ndataloader_val = DataLoader(\n    VAL_DATASET,\n    batch_size=1,\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-23T15:54:42.522503Z","iopub.execute_input":"2024-02-23T15:54:42.523064Z","iopub.status.idle":"2024-02-23T15:54:42.53301Z","shell.execute_reply.started":"2024-02-23T15:54:42.523027Z","shell.execute_reply":"2024-02-23T15:54:42.531411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"net.eval()\n\nmetric = Accuracy(task='binary')\n\nlabels = []\npredictions = []\n\nwith torch.no_grad():\n    for data, label in dataloader_val:\n        output = net.forward(data)\n        prediction = round(output.numpy().flatten()[0])\n#         print(f\"Ground Truth Label: {label[0]}, Prediction: {prediction}\")\n        metric(output, label)\n        labels.append(label)\n        predictions.append(prediction)\n    acc = metric.compute()\n    \n    print(f\"Validation Accuracy: {acc*100:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-02-23T15:54:44.448756Z","iopub.execute_input":"2024-02-23T15:54:44.449261Z","iopub.status.idle":"2024-02-23T15:54:45.256762Z","shell.execute_reply.started":"2024-02-23T15:54:44.449226Z","shell.execute_reply":"2024-02-23T15:54:45.255786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20, 12))\nsns.heatmap(confusion_matrix(labels, outputs), annot=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-23T15:54:48.341854Z","iopub.execute_input":"2024-02-23T15:54:48.342514Z","iopub.status.idle":"2024-02-23T15:54:48.697497Z","shell.execute_reply.started":"2024-02-23T15:54:48.342479Z","shell.execute_reply":"2024-02-23T15:54:48.696487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metric = Accuracy(task='binary')\n\nwith torch.no_grad():\n    for data, label in dataloader_train:\n        output = net.forward(data)\n        prediction = round(output.numpy().flatten()[0])\n#         print(f\"Ground Truth Label: {label[0]}, Prediction: {prediction}\")\n        metric(output, label)\n    acc = metric.compute()\n    \n    print(f\"Accuracy: {acc*100:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-02-23T15:54:48.941611Z","iopub.execute_input":"2024-02-23T15:54:48.942749Z","iopub.status.idle":"2024-02-23T15:54:51.296171Z","shell.execute_reply.started":"2024-02-23T15:54:48.942679Z","shell.execute_reply":"2024-02-23T15:54:51.294999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(net.state_dict(), 'weights.pth')","metadata":{"execution":{"iopub.status.busy":"2024-02-23T15:54:51.298223Z","iopub.execute_input":"2024-02-23T15:54:51.298562Z","iopub.status.idle":"2024-02-23T15:54:51.306111Z","shell.execute_reply.started":"2024-02-23T15:54:51.298534Z","shell.execute_reply":"2024-02-23T15:54:51.304851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"net = TumorClassifier()\nnet.load_state_dict(torch.load('weights.pth'))","metadata":{"execution":{"iopub.status.busy":"2024-02-23T15:54:51.307855Z","iopub.execute_input":"2024-02-23T15:54:51.308315Z","iopub.status.idle":"2024-02-23T15:54:51.325088Z","shell.execute_reply.started":"2024-02-23T15:54:51.308271Z","shell.execute_reply":"2024-02-23T15:54:51.324068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### test dataloader\ntest_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Grayscale(),\n])\n\nTEST_DIR = '/kaggle/working/test/'\nTEST_DATASET = ImageFolder(root=TEST_DIR, transform=test_transforms)\n\ndataloader_test = DataLoader(\n    TEST_DATASET,\n    batch_size=1,\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-23T15:54:53.096739Z","iopub.execute_input":"2024-02-23T15:54:53.098184Z","iopub.status.idle":"2024-02-23T15:54:53.105593Z","shell.execute_reply.started":"2024-02-23T15:54:53.098141Z","shell.execute_reply":"2024-02-23T15:54:53.104046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_metric = Accuracy(task='binary')\n\nnet.eval()\n\nwith torch.no_grad():\n    for data, label in dataloader_test:\n        output = net.forward(data)\n        prediction = round(output.numpy().flatten()[0])\n        print(f\"Ground Truth Label: {label[0]}, Prediction: {prediction}\")\n        test_metric(output, label)\n        \n    test_acc = test_metric.compute()\n    print(f\"Test Accuracy: {test_acc*100:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-02-23T15:54:53.765181Z","iopub.execute_input":"2024-02-23T15:54:53.765651Z","iopub.status.idle":"2024-02-23T15:54:53.922471Z","shell.execute_reply.started":"2024-02-23T15:54:53.765618Z","shell.execute_reply":"2024-02-23T15:54:53.920952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}